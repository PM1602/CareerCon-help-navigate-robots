{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "      try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2024)])\n",
    "      except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denoising the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following code snippets were taken from https://www.kaggle.com/theoviel/fast-fourier-transform-denoising\n",
    "from numpy.fft import *\n",
    "\n",
    "def filter_signal(signal, threshold=1e3):\n",
    "    fourier = rfft(signal)\n",
    "    frequencies = rfftfreq(signal.size, d=20e-3/signal.size)\n",
    "    fourier[frequencies > threshold] = 0\n",
    "    return irfft(fourier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above function the numpy's fft library(fourier tranform) was used and then frequncies were computed and then the inverse fourier transform was applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(dataset):\n",
    "    dataset['resultant_orientation']=np.sqrt((dataset['orientation_X'])**2+(dataset['orientation_Y'])**2+(dataset['orientation_Z'])**2+(dataset['orientation_W'])**2)\n",
    "    dataset['resultant_angular_velocity']=np.sqrt((dataset['angular_velocity_X'])**2+(dataset['angular_velocity_Y'])**2+(dataset['angular_velocity_Z'])**2)\n",
    "    dataset['resultant_linear_acceleration']=np.sqrt((dataset['linear_acceleration_X'])**2+(dataset['linear_acceleration_Y'])**2+(dataset['linear_acceleration_Z'])**2)\n",
    "    \n",
    "    dataset['resultant_orientation_sum']=np.sqrt(((dataset['orientation_X'])**2+(dataset['orientation_Y'])**2+(dataset['orientation_Z'])**2+(dataset['orientation_W'])**2))/(dataset['orientation_X']+dataset['orientation_Y']+dataset['orientation_Z']+dataset['orientation_W'])\n",
    "    dataset['resultant_angular_velocity_sum']=np.sqrt(((dataset['angular_velocity_X'])**2+(dataset['angular_velocity_Y'])**2+(dataset['angular_velocity_Z'])**2))/(dataset['angular_velocity_X']+dataset['angular_velocity_Y']+dataset['angular_velocity_Z'])\n",
    "    dataset['resultant_linear_acceleration_sum']=np.sqrt(((dataset['linear_acceleration_X'])**2+(dataset['linear_acceleration_Y'])**2+(dataset['linear_acceleration_Z'])**2))/(dataset['linear_acceleration_X']+dataset['linear_acceleration_Y']+dataset['linear_acceleration_Z'])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell we calculated the resultant of each sensor feature by square rooting the sum of the square of the feaures coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistical_features(X_data):\n",
    "    #Drop unwanted features\n",
    "#     output_X_data = X_data.drop(['surface','row_id','measurement_number','group_id'],axis=1)\n",
    "\n",
    "    #Group by series \n",
    "    output_stat_series=pd.DataFrame()\n",
    "\n",
    "    for col in X_data.columns:\n",
    "        if col not in ['series_id', 'measurement_number','row_id']:\n",
    "            output_stat_series[col+'_mean']=X_data.groupby('series_id')[col].mean()\n",
    "            output_stat_series[col+'_median']=X_data.groupby('series_id')[col].median()\n",
    "            output_stat_series[col+'_max']=X_data.groupby('series_id')[col].max()\n",
    "            output_stat_series[col+'_min']=X_data.groupby('series_id')[col].min()\n",
    "            output_stat_series[col+'_var']= X_data.groupby('series_id')[col].var()\n",
    "            output_stat_series[col+'_std']= X_data.groupby('series_id')[col].std()\n",
    "            output_stat_series[col+'_quant'] = X_data.groupby('series_id')[col].quantile()\n",
    "            output_stat_series[col+'_skew']= X_data.groupby('series_id')[col].skew()\n",
    "            output_stat_series[col + '_mad'] = X_data.groupby(['series_id'])[col].apply(lambda x: np.median(np.abs(np.diff(x))))\n",
    "            output_stat_series[col + '_abs_max'] = X_data.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n",
    "            output_stat_series[col + '_abs_min'] = X_data.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n",
    "    series_ids = np.unique(X_data['series_id'])\n",
    "\n",
    "    \n",
    "    return output_stat_series #x_data_final,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell we used aggregate functions mean,var,std on the features orintaiton,angular velocity and linear acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above cell is the denoised data with original ,statistical and manually computed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_set=pd.read_csv('X_test_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_denoised = test_data_set.copy()\n",
    "# X_test_denoised=X_test_denoised.sample(n=1)\n",
    "for col in test_data_set.columns:      \n",
    "    if col[0:3] == 'ang' or col[0:3] == 'lin':\n",
    "        # Apply filter_signal function to the data in each series\n",
    "        denoised_data = test_data_set.groupby(['series_id'])[col].apply(lambda x: filter_signal(x))\n",
    "        # Assign the denoised data back to X_train\n",
    "        list_denoised_data = []\n",
    "        for arr in denoised_data:\n",
    "            for val in arr:\n",
    "                list_denoised_data.append(val)\n",
    "        X_test_denoised[col] = list_denoised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_Pipeline(test_df):\n",
    "#     X_test_denoised=X_test_denoised.sample(n=1)\n",
    "    #randomly sampled one row and computed the features\n",
    "    X_test_denoised=new_features(test_df)\n",
    "    X_test_denoised=compute_statistical_features(X_test_denoised)\n",
    "    final_model = joblib.load('lgbm_model_new.pkl')\n",
    "    y_prob = final_model.predict(X_test_denoised)\n",
    "    return y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data=X_test_denoised.sample(n=1)\n",
    "y_pred=Final_Pipeline(sample_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
